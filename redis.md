# Redis 数据类型

## 1. 字符串（String）

字符串是 Redis 中最基本的数据类型，可以包含任何类型的数据，比如整数、浮点数、二进制数据（如图片或文件内容）。

**常用命令：**

- SET：设置一个键的值。
- GET：获取指定键的值。
- INCR：增加键的整数值。
- DECR：减少键的整数值。
- APPEND：追加字符串到指定键的值。

**示例：**

```bash
SET mykey "Hello, Redis!"
GET mykey  # 返回 "Hello, Redis!"
INCR counter  # counter 值增加 1
```

## 2. 哈希（Hash）

哈希是一个键值对集合，适用于存储对象类型的数据。每个哈希都有一个键，可以包含多个字段和值。

**常用命令：**

- HSET：设置哈希表中字段的值。
- HGET：获取哈希表中指定字段的值。
- HGETALL：获取哈希表中的所有字段和值。
- HDEL：删除哈希表中的字段。

**示例：**

```bash
HSET user:1000 name "John" age 30
HGET user:1000 name  # 返回 "John"
HGETALL user:1000  # 返回所有字段和值
```

## 3. 列表（List）

列表是一个有序的字符串集合，可以进行操作，如推送（push）或弹出（pop）元素。列表支持从两端进行操作。

**常用命令：**

- LPUSH：将一个或多个值插入列表的左边。
- RPUSH：将一个或多个值插入列表的右边。
- LPOP：从列表的左边弹出一个值。
- RPOP：从列表的右边弹出一个值。
- LRANGE：获取列表的指定范围的元素。

**示例：**

```bash
LPUSH mylist "A" "B" "C"
LRANGE mylist 0 -1  # 返回 ["C", "B", "A"]
RPOP mylist  # 返回 "A"
```

## 4. 集合（Set）

集合是一个无序的字符串集合，其中每个元素都是唯一的。适合用于存储不重复的数据，支持集合运算如交集、并集和差集。

**常用命令：**

- SADD：向集合添加一个或多个成员。
- SMEMBERS：获取集合中的所有成员。
- SISMEMBER：检查某个成员是否在集合中。
- SPOP：从集合中移除并返回一个随机成员。

**示例：**

```bash
SADD myset "apple" "banana" "orange"
SMEMBERS myset  # 返回 ["apple", "banana", "orange"]
SISMEMBER myset "apple"  # 返回 1 (true)
SPOP myset  # 随机移除一个元素
```

## 5. 有序集合（Sorted Set）

有序集合类似于集合，但每个元素都会关联一个分数（score）。Redis 会根据分数对元素进行排序。适合用于排名系统、权重系统等。

**常用命令：**

- ZADD：向有序集合添加一个或多个成员，或者更新已存在成员的分数。
- ZRANGE：获取有序集合指定范围的成员。
- ZREM：从有序集合中删除一个或多个成员。
- ZINCRBY：增加有序集合中成员的分数。

**示例：**

```bash
ZADD leaderboard 100 "Alice" 200 "Bob" 150 "Charlie"
ZRANGE leaderboard 0 -1  # 返回 ["Alice", "Charlie", "Bob"]
ZINCRBY leaderboard 50 "Alice"  # Alice 的分数增加 50
```

## 6. 位图（Bitmap）

位图是 Redis 中的一种非常高效的存储方式，用于处理大量的二进制数据，尤其适用于做大量的 true/false 类型的记录。Redis 位图实际上是通过对字符串进行位操作来实现的。

**常用命令：**

- SETBIT：设置指定位置的位（0 或 1）。
- GETBIT：获取指定位置的位。
- BITCOUNT：计算位图中值为 1 的位的数量。

**示例：**

```bash
SETBIT mybitmap 7 1  # 将第7位设置为1
GETBIT mybitmap 7  # 返回 1
BITCOUNT mybitmap  # 返回当前位图中1的数量
```

## 7. HyperLogLog

HyperLogLog 是一种基于概率的数据结构，用于做基数统计。它的特点是能够用非常少的内存来估算大型数据集的不同元素的数量。

**常用命令：**

- PFADD：将指定的元素添加到 HyperLogLog 中。
- PFCOUNT：返回 HyperLogLog 中不同元素的估算数量。

**示例：**

```bash
PFADD myhll "apple" "banana" "cherry"
PFCOUNT myhll  # 返回估算的不同元素数量
```

## 8. 地理空间（Geo）

Redis 提供了对地理空间数据的支持，可以存储地理位置并进行查询。

**常用命令：**

- GEOADD：将一个或多个地理位置添加到 Redis 中。
- GEODIST：计算两个地理位置之间的距离。
- GEORADIUS：查询某个范围内的地理位置。

**示例：**

```bash
GEOADD cities 13.361389 38.115556 "Palermo" 15.087269 37.502669 "Catania"
GEODIST cities "Palermo" "Catania"  # 计算两个位置的距离
```

## 总结

Redis 提供了多种灵活的数据结构来满足不同的业务需求。通过使用不同的 Redis 数据类型，开发者可以在内存数据库中进行高效的数据存储、处理和查询。不同的数据类型适用于不同的场景，例如：

- 字符串适合存储简单的键值对数据；
- 哈希适合存储对象数据；
- 列表和集合适合存储有序和无序的集合数据；
- 有序集合适合处理带有排序的数据；
- 位图适合进行高效的位级操作；
- HyperLogLog 适合进行基数统计；
- Geo 适合进行地理位置查询。

# Redis 持久化

Redis 持久化是 Redis 提供的一项功能，用于将数据从内存持久化到磁盘，确保即使在 Redis 重启时，数据也不会丢失。Redis 提供了两种主要的持久化方式：RDB（快照持久化）和 AOF（追加文件持久化），你可以根据业务需求选择适合的持久化方式。

## 1. RDB（Redis 数据库快照）持久化

RDB 是 Redis 的一种持久化方式，它通过在指定的时间间隔内生成数据的快照来保存数据。

### 工作原理：

- Redis 会在内存中创建一个时间点的快照，将所有数据保存到磁盘上的 RDB 文件中。
- 当 Redis 进程退出时，RDB 会保留最后一个时间点的快照，重启时加载该文件来恢复数据。

### 配置：

在 redis.conf 配置文件中，你可以通过设置 save 指令来配置 RDB 的生成条件。每当满足某个条件时，Redis 会创建 RDB 快照。例如：

```bash
save 900 1   # 900秒（15分钟）内，如果有至少 1 个键被修改，则生成快照
save 300 10  # 300秒（5分钟）内，如果有至少 10 个键被修改，则生成快照
save 60 10000 # 60秒内，如果有至少 10000 个键被修改，则生成快照
```

### 优缺点：

**优点：**

- 生成 RDB 文件后不会影响 Redis 的性能。
- 可以进行完整备份，适合做数据备份。
- 恢复数据速度较快。
  **缺点：**
  — 数据不完全实时，快照之间的数据会丢失，可能会导致数据丢失。

## 2. AOF（Append-Only File）追加文件持久化

AOF 是另一种持久化方式，它通过记录所有写命令到日志文件中来保存数据。每次执行修改操作时，Redis 会将相应的写命令（如 SET, INCR 等）追加到 AOF 文件末尾。

### 工作原理：

- 每当 Redis 执行写操作时，它会将相应的命令记录到 AOF 文件中。
- 在 Redis 重启时，Redis 会读取 AOF 文件并按照文件中的命令重新执行，从而恢复数据。

### 配置：

在 redis.conf 配置文件中，你可以配置 AOF 相关的参数：

```bash
appendonly yes         # 启用 AOF 持久化
appendfsync everysec   # 每秒同步一次 AOF 文件
```

### AOF 还支持几种同步方式，可以通过 appendfsync 参数配置：

- always：每次写操作后都会同步 AOF 文件（性能较差）。
- everysec：每秒同步一次（常用设置，性能较好）。
- no：不主动同步（AOF 写入速度较快，但可能丢失数据）。

### 优缺点：

**优点：**

- 相比 RDB，AOF 适合实时性要求较高的应用，可以最大限度地减少数据丢失。
- 即使 Redis 崩溃，丢失的数据也较少（除非 AOF 文件没有同步）。
  **缺点：**
- AOF 文件较大，恢复时需要执行更多的写命令，恢复速度比 RDB 慢。
- AOF 文件随着时间推移可能变得非常大，需要进行重写（即 BGREWRITEAOF）来优化 AOF 文件。

## 3. 混合持久化（RDB + AOF）

Redis 还支持同时启用 RDB 和 AOF 持久化方式，以充分发挥两者的优势。

- 在这种模式下，Redis 会定期保存 RDB 快照，同时也会记录 AOF 日志。
- 启用混合持久化时，可以将数据的恢复速度和实时性结合起来，确保数据的持久化和恢复效率。

### 配置：

在 redis.conf 中启用 AOF 持久化，同时启用 RDB 快照：

```bash
save 900 1
save 300 10
save 60 10000
appendonly yes
appendfsync everysec
```

## 4. 持久化选择和恢复策略

RDB 适合：定期备份数据，数据丢失容忍度较高。

- AOF 适合：实时性要求高的应用，需要最小化数据丢失。
- 混合持久化适合：既需要数据恢复速度又要求较低的实时性，结合 RDB 和 AOF 的优点。

## 5. 持久化的后台操作

Redis 还提供了一些后台命令用于处理 RDB 和 AOF 文件，比如：

- BGSAVE：在后台生成 RDB 快照。
- BGREWRITEAOF：在后台重写 AOF 文件以减小其大小。

**总结**

- RDB 和 AOF 各有优缺点，适用于不同的场景。
- 如果希望高性能的同时容忍一定的数据丢失，使用 RDB。
- 如果实时性要求较高，需要最大程度减少数据丢失，则使用 AOF。
- 可以结合使用 RDB 和 AOF，结合两者的优点来提高持久化的可靠性和性能。

# 缓存和 DB 一致性方案

## 1. 什么是缓存和 DB 的数据一致性？

- 缓存有数据 缓存的数据值需和 DB 相同
- 缓存无数据 DB 是最新值

#### 一致性就是数据保持一致，在分布式系统中，可以理解为多个节点中数据的值是一致的。

- 强一致性：这种一致性级别是最符合用户直觉的，它要求系统写入什么，读出来的也会是什么，用户体验好，但实现起来往往对系统的性能影响大
- 弱一致性：这种一致性级别约束了系统在写入成功后，不承诺立即可以读到写入的值，也不承诺多久之后数据能够达到一致，但会尽可能地保证到某个时间级别（比如秒级别）后，数据能够达到一致状态
- 最终一致性：最终一致性是弱一致性的一个特例，系统会保证在一定时间内，能够达到一个数据一致的状态。这里之所以将最终一致性单独提出来，是因为它是弱一致性中非常推崇的一种一致性模型，也是业界在大型分布式系统的数据一致性上比较推崇的模型

#### 缓存可以提升性能、缓解数据库压力，但是使用缓存也会导致数据不一致性的问题。一般我们是如何使用缓存呢？有三种经典的缓存模式：

- Cache-Aside Pattern
- Read-Through/Write through
- Write behind

**Cache-Aside Pattern**，即旁路缓存模式，它的提出是为了尽可能
Cache-Aside Pattern 的读请求流程如下：
![](/assets/redis_cache_1.png)

1. 读的时候，先读缓存，缓存命中的话，直接返回数据
2. 缓存没有命中的话，就去读数据库，从数据库取出数据，放入缓存后，同时返回响应。

Cache-Aside Pattern 的写请求流程如下：
![](/assets/redis_cache_2.png)

**Read-Through/Write through** 实际只是在 **Cache-Aside Pattern** 之上进行了一层封装，它会让程序代码变得更简洁，同时也减少数据源上的负载。

**Write behind**跟**Read-Through/Write-Through**有相似的地方，都是由**Cache Provider**来负责缓存和数据库的读写。它两又有个很大的不同：**Read/Write Through**是同步更新缓存和数据的，**Write Behind**则是只更新缓存，不直接更新数据库，通过批量异步的方式来更新数据库。
![](/assets/redis_cache_3.png)
这种方式下，缓存和数据库的一致性不强，**对一致性要求高的系统要谨慎使用**。但是它适合频繁写的场景，MySQL 的 InnoDB Buffer Pool 机制就使用到这种模式。

## 2. 操作缓存的时候，删除缓存呢，还是更新缓存？

#### 一般业务场景，我们使用的就是 Cache-Aside 模式。为什么是删除缓存而不是更新缓存呢？

假设有 A、B 两个请求，请求 A 做更新操作，请求 B 做查询读取操作。
![](/assets/redis_cache_4.png)
我们在操作缓存的时候，到底应该删除缓存还是更新缓存呢？我们先来看个例子：
![](/assets/redis_cache_5.png)

1. 线程 A 先发起一个写操作，第一步先更新数据库
1. 线程 B 再发起一个写操作，第二步更新了数据库
1. 由于网络等原因，线程 B 先更新了缓存
1. 线程 A 更新缓存。

这时候，缓存保存的是 A 的数据（老数据），数据库保存的是 B 的数据（新数据），数据**不一致**了，脏数据出现啦。如果是**删除缓存取代更新缓存**则不会出现这个脏数据问题。
**更新缓存相对于删除缓存**，还有两点劣势：

- 如果你写入的缓存值，是经过复杂计算才得到的话。更新缓存频率高的话，就浪费性能啦。
- 在写数据库场景多，读数据场景少的情况下，数据很多时候还没被读取到，又被更新了，这也浪费了性能呢(实际上，写多的场景，用缓存也不是很划算了)

#### 双写的情况下，先操作数据库还是先操作缓存？

**Cache-Aside**缓存模式中，在写入请求的时候，为什么是**先操作数据库**呢？为什么不**先操作缓存**呢？
假设有 A、B 两个请求，请求 A 做更新操作，请求 B 做查询读取操作。
![](/assets/redis_cache_6.png)

1. 线程 A 发起一个写操作，第一步 del cache
1. 此时线程 B 发起一个读操作，cache miss
1. 线程 B 继续读 DB，读出来一个老数据
1. 然后线程 B 把老数据设置入 cache
1. 线程 A 写入 DB 最新的数据

酱紫就有问题啦，**缓存和数据库的数据不一致了。缓存保存的是老数据，数据库保存的是新数据**。因此，Cache-Aside 缓存模式，选择了先操作数据库而不是先操作缓存。

#### 缓存延时双删

![](/assets/redis_cache_7.png)

1. 先删除缓存
1. 再更新数据库
1. 休眠一会（比如 1 秒），再次删除缓存。
   这个休眠一会，一般多久呢？都是 1 秒？
   > 这个休眠时间 = 读业务逻辑数据的耗时 + 几百毫秒。 为了确保读请求结束，写请求可以删除读请求可能带来的缓存脏数据。

#### 删除缓存重试机制

不管是**延时双删**还是**Cache-Aside 先操作数据库再删除缓存**，如果第二步的删除缓存失败呢，删除失败会导致脏数据

> 删除失败就多删除几次呀,保证删除缓存成功呀~ 所以可以引入删除缓存重试机制

![](/assets/redis_cache_8.png)

1. 写请求更新数据库
1. 缓存因为某些原因，删除失败
1. 把删除失败的 key 放到消息队列
1. 消费消息队列的消息，获取要删除的 key
1. 重试删除缓存操作

#### 读取 biglog 异步删除缓存

重试删除缓存机制还可以，就是会造成好多业务代码入侵。其实，还可以通过**数据库的 binlog 来异步淘汰 key**。
![](/assets/redis_cache_9.png)
以 mysql 为例 可以使用阿里的 canal 将 binlog 日志采集发送到 MQ 队列里面，然后通过 ACK 机制确认处理这条更新消息，删除缓存，保证数据缓存一致性

**总结**：

- 以上的方案没有绝对的那种的方案的好与不好；可以根据具体的业务需求，选择合适的方案

# 缓存 穿透，击穿，雪崩

- [缓存穿透](#缓存穿透)
  - [什么是缓存穿透？](#什么是缓存穿透)
  - [缓存穿透常用的解决方案](#缓存穿透常用的解决方案)
- [缓存击穿](#缓存击穿)
  - [什么是缓存击穿？](#什么是缓存击穿)
  - [缓存击穿危害](#缓存击穿危害)
  - [如何解决](#如何解决)
- [缓存雪崩](#缓存雪崩)
  - [什么是缓存雪崩？](#什么是缓存雪崩)
  - [缓存雪崩解决方案](#缓存雪崩解决方案)
- [缓存预热](#缓存预热)
  - [什么是缓存预热？](#什么是缓存预热)
  - [缓存预热的操作方法](#缓存预热的操作方法)
- [缓存降级](#缓存降级)

<!-- /TOC -->

<img src="https://cdn.jsdelivr.net/gh/CoderLeixiaoshuai/assets/202102/20210504215632-2021-05-04-21-56-33.png" alt="20210504215632-2021-05-04-21-56-33">

在实际生产环境中有时会遇到缓存穿透、缓存击穿、缓存雪崩等异常场景，为了避免异常带来巨大损失，我们需要了解每种异常发生的原因以及解决方案，帮助提升系统可靠性和高可用。

## 缓存穿透

### 什么是缓存穿透？

缓存穿透是指用户请求的数据在缓存中不存在即没有命中，同时在数据库中也不存在，导致用户每次请求该数据都要去数据库中查询一遍，然后返回空。

如果有恶意攻击者不断请求系统中不存在的数据，会导致短时间大量请求落在数据库上，造成数据库压力过大，甚至击垮数据库系统。

### 缓存穿透常用的解决方案

**（1）布隆过滤器（推荐）**

布隆过滤器（Bloom Filter，简称 BF）由 Burton Howard Bloom 在 1970 年提出，是一种空间效率高的概率型数据结构。

**布隆过滤器专门用来检测集合中是否存在特定的元素。**

如果在平时我们要判断一个元素是否在一个集合中，通常会采用查找比较的方法，下面分析不同的数据结构查找效率：

- 采用线性表存储，查找时间复杂度为 O(N)
- 采用平衡二叉排序树（AVL、红黑树）存储，查找时间复杂度为 O(logN)
- 采用哈希表存储，考虑到哈希碰撞，整体时间复杂度也要 O[log(n/m)]

当需要判断一个元素是否存在于海量数据集合中，不仅查找时间慢，还会占用大量存储空间。接下来看一下布隆过滤器如何解决这个问题。

**布隆过滤器设计思想**

布隆过滤器由一个长度为 m 比特的位数组（bit array）与 k 个哈希函数（hash function）组成的数据结构。位数组初始化均为 0，所有的哈希函数都可以分别把输入数据尽量均匀地散列。

当要向布隆过滤器中插入一个元素时，该元素经过 k 个哈希函数计算产生 k 个哈希值，以哈希值作为位数组中的下标，将所有 k 个对应的比特值由 0 置为 1。

当要查询一个元素时，同样将其经过哈希函数计算产生哈希值，然后检查对应的 k 个比特值：如果有任意一个比特为 0，表明该元素一定不在集合中；如果所有比特均为 1，表明该集合有可能性在集合中。为什么不是一定在集合中呢？因为不同的元素计算的哈希值有可能一样，会出现哈希碰撞，导致一个不存在的元素有可能对应的比特位为 1，这就是所谓“假阳性”（false positive）。相对地，“假阴性”（false negative）在 BF 中是绝不会出现的。

总结一下：布隆过滤器认为不在的，一定不会在集合中；布隆过滤器认为在的，可能在也可能不在集合中。

举个例子：下图是一个布隆过滤器，共有 18 个比特位，3 个哈希函数。集合中三个元素 x，y，z 通过三个哈希函数散列到不同的比特位，并将比特位置为 1。当查询元素 w 时，通过三个哈希函数计算，发现有一个比特位的值为 0，可以肯定认为该元素不在集合中。

<div align="center">  <img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201025213820.png" width="500"/> </div><br>

**布隆过滤器优缺点**

优点：

- 节省空间：不需要存储数据本身，只需要存储数据对应 hash 比特位
- 时间复杂度低：插入和查找的时间复杂度都为 O(k)，k 为哈希函数的个数

缺点：

- 存在假阳性：布隆过滤器判断存在，可能出现元素不在集合中；判断准确率取决于哈希函数的个数
- 不能删除元素：如果一个元素被删除，但是却不能从布隆过滤器中删除，这也是造成假阳性的原因了

**布隆过滤器适用场景**

- 爬虫系统 url 去重
- 垃圾邮件过滤
- 黑名单

**（2）返回空对象**

当缓存未命中，查询持久层也为空，可以将返回的空对象写到缓存中，这样下次请求该 key 时直接从缓存中查询返回空对象，请求不会落到持久层数据库。为了避免存储过多空对象，通常会给空对象设置一个过期时间。

这种方法会存在两个问题：

- 如果有大量的 key 穿透，缓存空对象会占用宝贵的内存空间。
- 空对象的 key 设置了过期时间，在这段时间可能会存在缓存和持久层数据不一致的场景。

## 缓存击穿

### 什么是缓存击穿？

缓存击穿，是指一个 key 非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个 key 在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。

### 缓存击穿危害

数据库瞬时压力骤增，造成大量请求阻塞。

### 如何解决

**使用互斥锁（mutex key）**

这种思路比较简单，就是让一个线程回写缓存，其他线程等待回写缓存线程执行完，重新读缓存即可。

<div align="center">  <img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201025213939.png" width="500"/> </div><br>

同一时间只有一个线程读数据库然后回写缓存，其他线程都处于阻塞状态。如果是高并发场景，大量线程阻塞势必会降低吞吐量。这种情况如何解决？大家可以在留言区讨论。

如果是分布式应用就需要使用分布式锁。

**热点数据永不过期**

永不过期实际包含两层意思：

- 物理不过期，针对热点 key 不设置过期时间
- 逻辑过期，把过期时间存在 key 对应的 value 里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建

<div align="center">  <img src="https://cdn.jsdelivr.net/gh/SmileLionCoder/assets@main/202010/20201025213959.png" width="500"/> </div><br>

从实战看这种方法对于性能非常友好，唯一不足的就是构建缓存时候，其余线程(非构建缓存的线程)可能访问的是老数据，对于不追求严格强一致性的系统是可以接受的。

## 缓存雪崩

### 什么是缓存雪崩？

缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，请求直接落到数据库上，引起数据库压力过大甚至宕机。和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。

### 缓存雪崩解决方案

常用的解决方案有：

- 均匀过期
- 加互斥锁
- 缓存永不过期
- 双层缓存策略

（1）均匀过期

设置不同的过期时间，让缓存失效的时间点尽量均匀。通常可以为有效期增加随机值或者统一规划有效期。

（2）加互斥锁

跟缓存击穿解决思路一致，同一时间只让一个线程构建缓存，其他线程阻塞排队。

（3）缓存永不过期

跟缓存击穿解决思路一致，缓存在物理上永远不过期，用一个异步的线程更新缓存。

（4）双层缓存策略

使用主备两层缓存：

主缓存：有效期按照经验值设置，设置为主读取的缓存，主缓存失效后从数据库加载最新值。

备份缓存：有效期长，获取锁失败时读取的缓存，主缓存更新时需要同步更新备份缓存。

## 缓存预热

### 什么是缓存预热？

缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统，这样就可以避免在用户请求的时候，先查询数据库，然后再将数据回写到缓存。

如果不进行预热， 那么 Redis 初始状态数据为空，系统上线初期，对于高并发的流量，都会访问到数据库中， 对数据库造成流量的压力。

### 缓存预热的操作方法

- 数据量不大的时候，工程启动的时候进行加载缓存动作；
- 数据量大的时候，设置一个定时任务脚本，进行缓存的刷新；
- 数据量太大的时候，优先保证热点数据进行提前加载到缓存。

## 缓存降级

缓存降级是指缓存失效或缓存服务器挂掉的情况下，不去访问数据库，直接返回默认数据或访问服务的内存数据。

在项目实战中通常会将部分热点数据缓存到服务的内存中，这样一旦缓存出现异常，可以直接使用服务的内存数据，从而避免数据库遭受巨大压力。

降级一般是有损的操作，所以尽量减少降级对于业务的影响程度。
